<=============================================================================>
=====>Title
DSOD: Learning Deeply Supervised Object Detectors from Scratch
=====>Main Contributions / New Opinions
1.未使用ImageNet模型进行参数初始化，而是直接利用Pascal VOC 2012数据集进行训练，得到的效果媲美其他四类检测方法
=====>Key Points
1.Proposal-free
Faster R-CNN以及R-FCN方法在VOC数据集上直接初始化训练，会失败。作者认为这与ROI Pooling相关，因为ROI Pooling需
要输入region proposal，而proposal-free类型的方法（SSD，YOLO）可以
2.Deep Supervision
参考DenseNet，利用skip connections实现supervised signals传递。Transition w/o Pooling Layer用这个层来增加dense
 blocks数量。原来的DenseNet的dense blocks数量是固定的
3.Stem Block
Stem Block受Inception-v3和v4的启发，定义Stem Block为三个3×3卷积层和一个2×2最大池化层，发现这么设计可以提升性能
4.Dense Prediction Structure
Learning Half and Reusing Half
In DSOD, in each scale (except scale-1), half of the feature maps are learned from the previous
scale with a series of conv-layers, while the remaining half feature maps are directly down-sampled from the 
contiguous high-resolution feature maps.
The pooling layeraims to match resolution to current size during concatenation.The 1X1 conv-layer is used to 
reduce the number of channels to 50%.
=====>Result
Method         data      pre-train     backbone network    prediction layer    speed(fps)   parameters   input_size   mAP
Faster RCNN    07+12     True          VGGNet              -                   7            134.7M       ~600X1000    73.2
Faster RCNN    07+12     True          ResNet101           -                   2.4          -            ~600X1000    76.4
SSD300         07+12     True          VGGNet              -                   46           26.3M        300X300      75.8
DSOD300        07+12     False         DS/64-192-48-1      Plain               20.6         18.2M        300X300      77.3
DSOD300        07+12     False         DS/64-192-48-1      Dense               17.4         14.8M        300X300      77.7

<=============================================================================>
=====>Title
Feature-Fused SSD: Fast Detection for Small Objects
=====>Main Contributions / New Opinions
1.Feature Fusion
Conv4_3、Conv5_3 Concatenation
Conv4_3、Conv5_3 Element-wise sum
=====>Key Points
1.Concatenation
Conv4_3(512X38X38) -----> Conv(3X3X512)    ----->Normalize(20)  ----->  ReLU  ===========================>
                                                                                                          ===>Concat(1024X38X38) ===>Conv(1X1X512) ===>Fusion(512X38X38)
Conv5_3(512X19X19) -----> Deconv(2X2X512)  ----->Conv(3X3X512)  ----->Normalize(10)  -----> ReLU  =======>

2.Element-wise sum
Conv4_3(512X38X38) -----> Conv(3X3X512)    ----->Normalize(20)  ===========================>
                                                                                            ===>Element-wise sum ===> ReLU  ===>Fusion(512X38X38)
Conv5_3(512X19X19) -----> Deconv(2X2X512)  ----->Conv(3X3X512)  ----->Normalize(10)  =======>
=====>Result
Method                   mAP
SSD300                   77.2
Element-wise sum         78.9
Concat                   78.8

<=============================================================================>
=====>Title
Xception: Deep Learning with Depthwise Separable Convolutions 
=====>Key Points
使用Depthwise Separable Convolution减少运算量，但是并未减少参数量，原因在于作者
加宽了网络
Depthwise Separable Convolutions既减少运算量，也减少参数量
example:
设卷积核K大小为Dk*Dk，输入特征图F大小为Df*Df*M,输出特征图G大小为Dg*Dg*N，其中Df=Dg，
即卷积不改变特征图大小，
===>standard convolution：
parameters：M*Dk*Dk*N
computational cost：Df*Df*Dk*Dk*M*N

===>depthwise separable convolution：
1.depthwise convolution：
parameters：M*1*Dk*Dk*1
computational cost：Df*Df*Dk*Dk*M
2.pointwise concatenation:
parameters：M*1*1*N
computational cost：Df*Df*1*1*M*N

===>comparison：
parameters:
standard/depthwise-separable = (M*Dk*Dk*N)/(M*1*Dk*Dk*1+M*1*1*N)
computational cost：
standard/depthwise-separable = (Df*Df*Dk*Dk*M*N)/(Df*Df*Dk*Dk*M+Df*Df*1*1*M*N)

<=============================================================================>




















